
CIS 520 - Programming Project #1
                   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Brian Cain <bccain@ksu.edu>
Carlos Salazar <csalazar@ksu.edu>
Owen Praeger <owenp@ksu.edu>


---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for
>> the TA, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation,
>> course text, lecture notes, and course staff.

It took us a while to set up git, but we finally got everything working 
like we wanted.


                 ALARM CLOCK
                 ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.


static struct list wait_list;

- This is our wait list for threads. We add threads to this list when
they need to wait and not be in the ready list.

struct semaphore sema;

-This was added to the struct thread. Each thread needs its own struct
so that it can signal and wait.

struct list_elem waitalem;

-This is the list element for all of the waiting threads

int64_t wakeup;

-This is the wakeup time variable for the struct thread. You need this variable to
give each thread its wakeup time.

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to your timer_sleep(),
>> including the effects of the timer interrupt handler.

Timer_sleep() is first called and records the start time and wakeuptime. We
then disable interupts, create a new thread t, and set that specific threads
wakeup time to the wakeup time we recorded at the beginning of the function.
We then push our new thread onto the waitlist and call sema_down to wait. 
After this we enable interupts.

Another function that had to be changed was timer_interrupt. We first
increment ticks by 1 and call thread_tick() to keep track of ticks.
We then have to enumerate through the wait list using a for loop, get the
thread in the wait list and see if its wakeup time is less than ticks. If
that's true signal and remove the thread from the wait list.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

To minimize the time spent within the timer interrupt handler, we made sure to only
enumerate through the wait list and check if their wake up time was less than
the number of ticks. If that was true then we removed that thread from the 
wait list so that it was confirmed that the thread was not waiting any more.


---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

Semaphores prevent multiple threads from calling the same section
of code. Using sema up and sema down threads can block off other
threads while the critical section of code is executing for 
that specific thread. While the threads are blocked, they are waiting
for the thread running the code to signal so they can run their 
  critical code.


>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

Similar to thread_sleep, we used semaphores to prevent race conditions.
In the critical section of the code, interupts are turned off by the
semaphore. This prevents race conditions.


---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> other designs that you considered?

Semaphores prevent race conditions and deadlock. It is also simplier than
trying to reimpliment thread blocking. Without the use of semaphores,
you would have deadlock and would cause the operating system to 
crash or halt.



             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.



>> B2: Explain the data structure used to track priority donation.

We used the built in doubly-linked list as well as a pointer for the
donee within our Donor list data structure. This doubly linked list
is a list of donors. We store the highest priority
of all the donated priorities in the threads priority field. Each
thread retains the base priority during execution. 


---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

We first used list_insert_ordered so that we would insert the thread
in order of priority. Secondly we have also sorted these lists
(for example, the semaphore.waiters list, the cond->waiters list,
  and the ready_list relating to threads.)
so that they would be in order as well. This will ensure that
the highest priority thread waiting on these locks, semaphores,
or condition variables wakes up first.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

A low priority thread has a lock that it is holding onto. A higher
priority thread is wanting the lock that the lower priority thread
currently holds on to. In order to force the lower priority thread
to relinquish the lock it donates its priority to the lower priority thread
so that the higher priority thread can use the lock to run. 

For nested donation handling, we have used our donee within the donor list.
This donee holds a pointer to a thread that has had its priority donated to it.
So if you have nested priority you can trace the donated priority from source to
the final recipient.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

There is a wait queue on the semaphore for the lock, the first thread on the wait queue for the
lock is the highest priority for that lock. So that thread will be the donor for the
lock holder. So we take the high priority thread and we remove its donation element 
which removes this thread from the donor list owned by lock holder. We recompute the
priority which demotes the lock holders priority and then the lock holder will release the semaphore
for the lock. This will open the lock to the high priority thread.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

Recompute thread priority is being executing at the same time that thread set priority 
is being executed upon the current thread. We disable interrupts so that what ever
update happens to the threads priority happens atomically. No, you cannot use a lock to avoid
this race. Two threads cannot execute thread_set_priority at the same time because there is only
one current thread at a time. The race condition comes from the thread priority being updated
at differeing locations.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

At first we thought about using a fixed sized array for priority but this does not allow
for deeply nested donations. Next we attempted to modify the list structure within pintos
  and use it like a priority stack. However this did not work at all and we had to 
  completely rethink our ideas for this project. We finally settled on using a
  donor list with donees along with an integer priority and a base priority. 
  This works with what we were trying to do.

              ADVANCED SCHEDULER [EXTRA CREDIT]
              =================================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0
 4
 8
12
16
20
24
28
32
36

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

